{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TermProject_multituning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMJq+ooKnKLTzlZcz5qWjb0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Haebuk/dataminingTP/blob/main/TermProject_multituning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYpSndCUKCS1",
        "outputId": "fb46dbb6-40b1-4eed-c07f-1159af2c6861"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCzLPBy-KJRQ",
        "outputId": "16f8aaea-d11c-4ddf-ad18-586b890d6670"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "!pip install https://s3-us-west-2.amazonaws.com/xgboost-nightly-builds/xgboost-1.4.0_SNAPSHOT%2B4224c08cacceba3f83f90e387c07aa6205a83bfa-py3-none-manylinux2010_x86_64.whl\n",
        "from tqdm import tqdm\n",
        "from sklearn.linear_model import LinearRegression, ElasticNet, Lasso,  Ridge, LassoLarsIC\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
        "from sklearn.model_selection import KFold, cross_val_score, train_test_split, TimeSeriesSplit\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import xgboost as xgb\n",
        "# After running\n",
        "! git clone --recursive https://github.com/Microsoft/LightGBM\n",
        "#You can run this oneliner which will build and compile LightGBM with GPU enabled in colab:\n",
        "! cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 ../../LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu;\n",
        "!mkdir -p /etc/OpenCL/vendors && \\ echo \"/usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd\n",
        "import lightgbm as lgb\n",
        "import re\n",
        "!pip install optuna -q\n",
        "import optuna\n",
        "from optuna.integration import XGBoostPruningCallback\n",
        "from sklearn.externals import joblib\n",
        "import pickle\n",
        "\n",
        "import matplotlib as mpl  # 기본 설정 만지는 용도\n",
        "import matplotlib.pyplot as plt  # 그래프 그리는 용도\n",
        "import matplotlib.font_manager as fm\n",
        "!apt-get update -qq\n",
        "!apt-get install fonts-nanum* -qq\n",
        "path = '/usr/share/fonts/truetype/nanum/NanumGothicEco.ttf'  # 설치된 나눔글꼴중 원하는 녀석의 전체 경로를 가져오자\n",
        "font_name = fm.FontProperties(fname=path, size=10).get_name()\n",
        "print(font_name)\n",
        "plt.rc('font', family=font_name)\n",
        "fm._rebuild()\n",
        "mpl.rcParams['axes.unicode_minus'] = False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting xgboost==1.4.0-SNAPSHOT+4224c08cacceba3f83f90e387c07aa6205a83bfa\n",
            "  Using cached https://s3-us-west-2.amazonaws.com/xgboost-nightly-builds/xgboost-1.4.0_SNAPSHOT%2B4224c08cacceba3f83f90e387c07aa6205a83bfa-py3-none-manylinux2010_x86_64.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost==1.4.0-SNAPSHOT+4224c08cacceba3f83f90e387c07aa6205a83bfa) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost==1.4.0-SNAPSHOT+4224c08cacceba3f83f90e387c07aa6205a83bfa) (1.19.5)\n",
            "Installing collected packages: xgboost\n",
            "  Found existing installation: xgboost 1.4.0-SNAPSHOT\n",
            "    Uninstalling xgboost-1.4.0-SNAPSHOT:\n",
            "      Successfully uninstalled xgboost-1.4.0-SNAPSHOT\n",
            "Successfully installed xgboost-1.4.0-SNAPSHOT\n",
            "fatal: destination path 'LightGBM' already exists and is not an empty directory.\n",
            "-- The C compiler identification is GNU 7.5.0\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Check for working C compiler: /usr/bin/cc\n",
            "-- Check for working C compiler: /usr/bin/cc -- works\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Found OpenMP_C: -fopenmp (found version \"4.5\") \n",
            "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\") \n",
            "-- Found OpenMP: TRUE (found version \"4.5\")  \n",
            "-- Looking for CL_VERSION_2_2\n",
            "-- Looking for CL_VERSION_2_2 - found\n",
            "-- Found OpenCL: /usr/lib/x86_64-linux-gnu/libOpenCL.so (found version \"2.2\") \n",
            "-- OpenCL include directory: /usr/include\n",
            "-- Boost version: 1.65.1\n",
            "-- Found the following Boost libraries:\n",
            "--   filesystem\n",
            "--   system\n",
            "-- Performing Test MM_PREFETCH\n",
            "-- Performing Test MM_PREFETCH - Success\n",
            "-- Using _mm_prefetch\n",
            "-- Performing Test MM_MALLOC\n",
            "-- Performing Test MM_MALLOC - Success\n",
            "-- Using _mm_malloc\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/LightGBM/build\n",
            "\u001b[35m\u001b[1mScanning dependencies of target _lightgbm\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target lightgbm\u001b[0m\n",
            "[  1%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/main.cpp.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt.cpp.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/boosting.cpp.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt_model_text.cpp.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/application/application.cpp.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/boosting.cpp.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt_prediction.cpp.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt.cpp.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/prediction_early_stop.cpp.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt_model_text.cpp.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/bin.cpp.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/config.cpp.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt_prediction.cpp.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/prediction_early_stop.cpp.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/bin.cpp.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/config.cpp.o\u001b[0m\n",
            "[ 24%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/config_auto.cpp.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/config_auto.cpp.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/dataset.cpp.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/dataset.cpp.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/dataset_loader.cpp.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/file_io.cpp.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/json11.cpp.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/dataset_loader.cpp.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/file_io.cpp.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/metadata.cpp.o\u001b[0m\n",
            "[ 39%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/json11.cpp.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/parser.cpp.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/train_share_states.cpp.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/metadata.cpp.o\u001b[0m\n",
            "[ 44%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/tree.cpp.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/parser.cpp.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/metric/dcg_calculator.cpp.o\u001b[0m\n",
            "[ 49%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/train_share_states.cpp.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/metric/metric.cpp.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/tree.cpp.o\u001b[0m\n",
            "[ 53%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/metric/dcg_calculator.cpp.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/metric/metric.cpp.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/ifaddrs_patch.cpp.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linker_topo.cpp.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linkers_mpi.cpp.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linkers_socket.cpp.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/network.cpp.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/ifaddrs_patch.cpp.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linker_topo.cpp.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/objective/objective_function.cpp.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/cuda_tree_learner.cpp.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/data_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 71%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linkers_mpi.cpp.o\u001b[0m\n",
            "[ 72%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linkers_socket.cpp.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/network.cpp.o\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/objective/objective_function.cpp.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/cuda_tree_learner.cpp.o\u001b[0m\n",
            "[ 78%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/data_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 79%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/feature_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 81%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/gpu_tree_learner.cpp.o\u001b[0m\n",
            "[ 82%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/feature_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 84%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/gpu_tree_learner.cpp.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/linear_tree_learner.cpp.o\u001b[0m\n",
            "[ 86%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/linear_tree_learner.cpp.o\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/serial_tree_learner.cpp.o\u001b[0m\n",
            "[ 89%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/tree_learner.cpp.o\u001b[0m\n",
            "[ 91%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/serial_tree_learner.cpp.o\u001b[0m\n",
            "[ 92%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/tree_learner.cpp.o\u001b[0m\n",
            "[ 94%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/voting_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 95%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/voting_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 97%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/c_api.cpp.o\u001b[0m\n",
            "[ 98%] \u001b[32m\u001b[1mLinking CXX shared library ../lib_lightgbm.so\u001b[0m\n",
            "[ 98%] Built target _lightgbm\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable ../lightgbm\u001b[0m\n",
            "[100%] Built target lightgbm\n",
            "running install\n",
            "running build\n",
            "running build_py\n",
            "INFO:root:Generating grammar tables from /usr/lib/python3.7/lib2to3/Grammar.txt\n",
            "INFO:root:Generating grammar tables from /usr/lib/python3.7/lib2to3/PatternGrammar.txt\n",
            "running egg_info\n",
            "writing lightgbm.egg-info/PKG-INFO\n",
            "writing dependency_links to lightgbm.egg-info/dependency_links.txt\n",
            "writing requirements to lightgbm.egg-info/requires.txt\n",
            "writing top-level names to lightgbm.egg-info/top_level.txt\n",
            "reading manifest template 'MANIFEST.in'\n",
            "no previously-included directories found matching 'build'\n",
            "warning: no files found matching 'LICENSE'\n",
            "warning: no files found matching '*.txt'\n",
            "warning: no files found matching '*.so' under directory 'lightgbm'\n",
            "warning: no files found matching 'compile/CMakeLists.txt'\n",
            "warning: no files found matching 'compile/cmake/IntegratedOpenCL.cmake'\n",
            "warning: no files found matching '*.so' under directory 'compile'\n",
            "warning: no files found matching '*.dll' under directory 'compile/Release'\n",
            "warning: no files found matching 'compile/external_libs/compute/CMakeLists.txt'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/compute/cmake'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/compute/include'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/compute/meta'\n",
            "warning: no files found matching 'compile/external_libs/eigen/CMakeLists.txt'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/Cholesky'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/Core'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/Dense'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/Eigenvalues'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/Geometry'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/Householder'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/Jacobi'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/LU'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/QR'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/SVD'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Cholesky'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Core'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Eigenvalues'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Geometry'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Householder'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Jacobi'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/LU'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/misc'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/plugins'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/QR'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/SVD'\n",
            "warning: no files found matching 'compile/external_libs/fast_double_parser/CMakeLists.txt'\n",
            "warning: no files found matching 'compile/external_libs/fast_double_parser/LICENSE'\n",
            "warning: no files found matching 'compile/external_libs/fast_double_parser/LICENSE.BSL'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/fast_double_parser/include'\n",
            "warning: no files found matching 'compile/external_libs/fmt/CMakeLists.txt'\n",
            "warning: no files found matching 'compile/external_libs/fmt/LICENSE.rst'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/fmt/include'\n",
            "warning: no files found matching '*' under directory 'compile/include'\n",
            "warning: no files found matching '*' under directory 'compile/src'\n",
            "warning: no files found matching 'LightGBM.sln' under directory 'compile/windows'\n",
            "warning: no files found matching 'LightGBM.vcxproj' under directory 'compile/windows'\n",
            "warning: no files found matching '*.dll' under directory 'compile/windows/x64/DLL'\n",
            "warning: no previously-included files matching '*.py[co]' found anywhere in distribution\n",
            "warning: no previously-included files found matching 'compile/external_libs/compute/.git'\n",
            "writing manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
            "running install_lib\n",
            "INFO:LightGBM:Installing lib_lightgbm from: ['../lib_lightgbm.so']\n",
            "copying ../lib_lightgbm.so -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "running install_egg_info\n",
            "removing '/usr/local/lib/python3.7/dist-packages/lightgbm-3.2.1.99-py3.7.egg-info' (and everything under it)\n",
            "Copying lightgbm.egg-info to /usr/local/lib/python3.7/dist-packages/lightgbm-3.2.1.99-py3.7.egg-info\n",
            "running install_scripts\n",
            "/bin/bash:  echo: command not found\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning:\n",
            "\n",
            "sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NanumGothic Eco\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRV_bgq_KKAv"
      },
      "source": [
        "PATH = '/content/drive/MyDrive/input/dataminingTP/'\n",
        "train_df = pd.read_csv(PATH + 'train_df_regex.csv')\n",
        "all_df = pd.read_csv(PATH + 'all_df.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "K5w61iPyKMnW",
        "outputId": "ce11bc40-2269-4727-95bc-0d8c852c4e8f"
      },
      "source": [
        "all_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dong</th>\n",
              "      <th>apt</th>\n",
              "      <th>year_of_completion</th>\n",
              "      <th>transaction_year_month</th>\n",
              "      <th>floor</th>\n",
              "      <th>top10</th>\n",
              "      <th>log_price</th>\n",
              "      <th>log_area</th>\n",
              "      <th>city_부산광역시</th>\n",
              "      <th>city_서울특별시</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>138</td>\n",
              "      <td>23</td>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>10.532123</td>\n",
              "      <td>4.452252</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>65</td>\n",
              "      <td>23</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>9.903538</td>\n",
              "      <td>4.606869</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65</td>\n",
              "      <td>23</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>10.558439</td>\n",
              "      <td>4.451319</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13</td>\n",
              "      <td>23</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>11.678448</td>\n",
              "      <td>4.993082</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13</td>\n",
              "      <td>23</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>11.695255</td>\n",
              "      <td>5.275202</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   dong  apt  year_of_completion  ...  log_area  city_부산광역시  city_서울특별시\n",
              "0   138   23                  41  ...  4.452252           0           1\n",
              "1    65   23                  12  ...  4.606869           0           1\n",
              "2    65   23                  46  ...  4.451319           0           1\n",
              "3    13   23                  42  ...  4.993082           0           1\n",
              "4    13   23                  43  ...  5.275202           0           1\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhHJgH3KKQH3",
        "outputId": "d75ea2cb-a0c1-4e04-bacf-59760828594b"
      },
      "source": [
        "train_df = all_df[:train_df.shape[0]]\n",
        "train_y = train_df['log_price']\n",
        "train_X = train_df.drop('log_price', axis=1)\n",
        "test_df = all_df[train_df.shape[0]:].drop('log_price', axis=1)\n",
        "print(train_df.shape, test_df.shape, train_X.shape, train_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1216553, 10) (5463, 9) (1216553, 9) (1216553,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEKwgUJvKRKe"
      },
      "source": [
        "def RMSE(y, y_pred):\n",
        "    rmse = mean_squared_error(y, y_pred) ** 0.5\n",
        "    return rmse\n",
        "\n",
        "def rmse_cv(model):\n",
        "    tscv = TimeSeriesSplit(n_splits=10)\n",
        "    rmse_list = []\n",
        "    for i, (train_index, test_index) in enumerate(tscv.split(train_X), start=1):\n",
        "        X_train, X_test = train_X.iloc[train_index], train_X.iloc[test_index]\n",
        "        y_train, y_test = train_y.iloc[train_index], train_y.iloc[test_index]\n",
        "        clf = model.fit(X_train, y_train)\n",
        "        pred = clf.predict(X_test)\n",
        "        rmse = RMSE(y_test, pred) \n",
        "        rmse_list.append(rmse)\n",
        "    return type(model).__name__, rmse_list\n",
        "\n",
        "def print_rmse_score(model):\n",
        "    model_name, score = rmse_cv(model)\n",
        "    for i, r in tqdm(enumerate(score, start=1), leave=True):\n",
        "        if i == 1:\n",
        "            print('\\n')\n",
        "            print(f'{i} FOLDS: {model_name} RMSE: {r:.4f}')\n",
        "        else:\n",
        "            print(f'{i} FOLDS: {model_name} RMSE: {r:.4f}')\n",
        "    print(f'\\n{model_name} mean RMSE: {np.mean(score):.4f}')\n",
        "    print('='*40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDFYtU9gKS3W",
        "outputId": "d1391c62-d16b-41ae-9900-426505eaf9be"
      },
      "source": [
        "cut = int(len(train_df)*0.8)\n",
        "h_train = train_df[:cut]\n",
        "h_valid = train_df[cut:]\n",
        "\n",
        "h_train_X = h_train.drop('log_price', axis=1)\n",
        "h_train_y = h_train['log_price']\n",
        "h_valid_X = h_valid.drop('log_price', axis=1)\n",
        "h_valid_y = h_valid['log_price']\n",
        "print(h_train_X.shape, h_train_y.shape, h_valid_X.shape, h_valid_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(973242, 9) (973242,) (243311, 9) (243311,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVOEPlynKV5O",
        "outputId": "7297a207-15d5-4e42-bc52-fac9dec7df4a"
      },
      "source": [
        "from optuna.samplers import TPESampler\n",
        "\n",
        "sampler = TPESampler(seed=10)\n",
        "n_repeats=3\n",
        "\n",
        "def objective(trial):\n",
        "    dtrain = xgb.DMatrix(h_train_X, label=h_train_y)\n",
        "    dtest = xgb.DMatrix(h_valid_X, label=h_valid_y)\n",
        "\n",
        "    param = {\n",
        "        'objective': 'reg:squarederror', # 회귀\n",
        "         'eval_metric': 'rmse',\n",
        "         \"xgb_gpu_hist\": 1,\n",
        "         'verbosity': 0,\n",
        "         'booster': 'gbtree', # gradient boosting decision tree\n",
        "         'lambda': trial.suggest_loguniform('lambda', 1e-8, 1),\n",
        "         'alpha': trial.suggest_loguniform('alpha', 1e-8, 1),\n",
        "         'max_depth': trial.suggest_int('max_depth',3, 9),\n",
        "         'learning_rate': 0.01,\n",
        "         \"eta\": trial.suggest_loguniform(\"eta\", 1e-8, 1.0),\n",
        "         \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-8, 1.0),\n",
        "         'n_estimators': trial.suggest_int('n_estimators', 700, 1500),\n",
        "         'min_child_weight': trial.suggest_int('min_child_weight', 0, 10),\n",
        "         'subsample': trial.suggest_loguniform('subsample', 0.4, 1)\n",
        "    }\n",
        "\n",
        "    model = xgb.XGBRegressor(**param)\n",
        "    pruning_callback = XGBoostPruningCallback(trial, \"validation_0-rmse\")\n",
        "    xgb_2 = model.fit(h_train_X, h_train_y, eval_set=[(h_valid_X, h_valid_y)], verbose=0,\n",
        "                      eval_metric='rmse', callbacks=[pruning_callback])\n",
        "\n",
        "    rmse = RMSE(h_valid_y, xgb_2.predict(h_valid_X))\n",
        "    return rmse\n",
        "        \n",
        "study_xgb = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "study_xgb.optimize(objective, n_trials=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-06-22 06:32:40,764]\u001b[0m A new study created in memory with name: no-name-fc6e92d4-90f7-4736-8c4e-c4e325164ed3\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-06-22 06:47:05,545]\u001b[0m Trial 0 finished with value: 0.20048695605053843 and parameters: {'lambda': 0.014810344004555135, 'alpha': 1.4656004675652718e-08, 'max_depth': 7, 'eta': 0.00978207662259244, 'gamma': 9.728728830009641e-05, 'n_estimators': 880, 'min_child_weight': 2, 'subsample': 0.8029815922829752}. Best is trial 0 with value: 0.20048695605053843.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-06-22 07:05:38,802]\u001b[0m Trial 1 finished with value: 0.19825546356718324 and parameters: {'lambda': 2.2536511574969237e-07, 'alpha': 5.090008568091192e-08, 'max_depth': 7, 'eta': 0.4237861601304585, 'gamma': 1.075439863800637e-08, 'n_estimators': 1110, 'min_child_weight': 8, 'subsample': 0.7011462565718398}. Best is trial 1 with value: 0.19825546356718324.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-06-22 07:23:04,708]\u001b[0m Trial 2 finished with value: 0.19466914964027004 and parameters: {'lambda': 0.005943503728075847, 'alpha': 2.1627610787257848e-06, 'max_depth': 9, 'eta': 0.005207224083783965, 'gamma': 0.00021895503882644017, 'n_estimators': 813, 'min_child_weight': 4, 'subsample': 0.7418647364337652}. Best is trial 2 with value: 0.19466914964027004.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-06-22 07:42:38,282]\u001b[0m Trial 3 finished with value: 0.19700041193136897 and parameters: {'lambda': 3.4250380089316126e-05, 'alpha': 2.965595722907858e-05, 'max_depth': 7, 'eta': 0.00012738137732610437, 'gamma': 0.0015965313667163816, 'n_estimators': 1181, 'min_child_weight': 8, 'subsample': 0.6451255817003931}. Best is trial 2 with value: 0.19466914964027004.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-06-22 07:52:10,545]\u001b[0m Trial 4 finished with value: 0.22448139824055505 and parameters: {'lambda': 0.18586218844499916, 'alpha': 3.5800468653895747e-06, 'max_depth': 3, 'eta': 2.544488269752405e-06, 'gamma': 8.163471763379958e-08, 'n_estimators': 1363, 'min_child_weight': 0, 'subsample': 0.7100430887666348}. Best is trial 2 with value: 0.19466914964027004.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 07:52:11,681]\u001b[0m Trial 5 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 07:52:12,971]\u001b[0m Trial 6 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 07:52:15,909]\u001b[0m Trial 7 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 07:52:17,086]\u001b[0m Trial 8 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 07:52:18,570]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-06-22 08:08:42,331]\u001b[0m Trial 10 finished with value: 0.19619392186577572 and parameters: {'lambda': 0.004771049358447906, 'alpha': 0.0037813496541665645, 'max_depth': 9, 'eta': 0.0007646719579318215, 'gamma': 1.3199428127910152e-06, 'n_estimators': 708, 'min_child_weight': 6, 'subsample': 0.4409150937815634}. Best is trial 2 with value: 0.19466914964027004.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-06-22 08:25:09,263]\u001b[0m Trial 11 finished with value: 0.1961657655233622 and parameters: {'lambda': 0.004599858839406615, 'alpha': 0.0026390797242517583, 'max_depth': 9, 'eta': 0.0014883597642016363, 'gamma': 7.494737705829735e-07, 'n_estimators': 702, 'min_child_weight': 5, 'subsample': 0.4401380819691161}. Best is trial 2 with value: 0.19466914964027004.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-06-22 08:46:03,113]\u001b[0m Trial 12 finished with value: 0.19591824314263673 and parameters: {'lambda': 0.0030644798765651167, 'alpha': 0.8393288421486518, 'max_depth': 9, 'eta': 0.004816129869748136, 'gamma': 1.5880075455229084e-07, 'n_estimators': 925, 'min_child_weight': 6, 'subsample': 0.41232561041602617}. Best is trial 2 with value: 0.19466914964027004.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-06-22 09:07:20,384]\u001b[0m Trial 13 finished with value: 0.19632215986504162 and parameters: {'lambda': 0.0006177657764288517, 'alpha': 0.9176263779035175, 'max_depth': 9, 'eta': 0.02320815919997651, 'gamma': 7.773479701767566e-05, 'n_estimators': 936, 'min_child_weight': 7, 'subsample': 0.49105122019851827}. Best is trial 2 with value: 0.19466914964027004.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 09:07:22,238]\u001b[0m Trial 14 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 09:07:23,959]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-06-22 09:28:50,692]\u001b[0m Trial 16 finished with value: 0.1952306780560345 and parameters: {'lambda': 2.741507682989658e-05, 'alpha': 0.0001895874240672076, 'max_depth': 9, 'eta': 5.660321759028145e-05, 'gamma': 0.9590242841479557, 'n_estimators': 1020, 'min_child_weight': 6, 'subsample': 0.7835397787362098}. Best is trial 2 with value: 0.19466914964027004.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 09:28:52,137]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 09:28:53,779]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 09:28:55,218]\u001b[0m Trial 19 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-06-22 09:45:02,904]\u001b[0m Trial 20 finished with value: 0.1953558328573 and parameters: {'lambda': 1.0199750970907447e-06, 'alpha': 1.1281390881066503e-05, 'max_depth': 9, 'eta': 8.85301304787785e-06, 'gamma': 3.8757962428025305e-05, 'n_estimators': 782, 'min_child_weight': 7, 'subsample': 0.8894388057910722}. Best is trial 2 with value: 0.19466914964027004.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-06-22 10:00:50,571]\u001b[0m Trial 21 finished with value: 0.19559177333760297 and parameters: {'lambda': 4.6303974724235135e-07, 'alpha': 1.911879833985384e-05, 'max_depth': 9, 'eta': 1.4955968280750403e-05, 'gamma': 3.2177690292555146e-05, 'n_estimators': 770, 'min_child_weight': 7, 'subsample': 0.8782568424000173}. Best is trial 2 with value: 0.19466914964027004.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 10:00:52,256]\u001b[0m Trial 22 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-06-22 10:16:45,824]\u001b[0m Trial 23 finished with value: 0.19588609689871253 and parameters: {'lambda': 2.502417615035982e-06, 'alpha': 5.13710685577996e-06, 'max_depth': 9, 'eta': 8.808384558317344e-06, 'gamma': 2.475719883365866e-05, 'n_estimators': 741, 'min_child_weight': 4, 'subsample': 0.7482607130630672}. Best is trial 2 with value: 0.19466914964027004.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 10:16:47,471]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 10:16:49,092]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 10:17:42,037]\u001b[0m Trial 26 pruned. Trial was pruned at iteration 40.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 10:17:43,735]\u001b[0m Trial 27 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 10:17:45,590]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 10:17:47,433]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 10:17:49,366]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 10:18:01,754]\u001b[0m Trial 31 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 10:20:00,066]\u001b[0m Trial 32 pruned. Trial was pruned at iteration 93.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 10:20:05,342]\u001b[0m Trial 33 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 10:20:06,970]\u001b[0m Trial 34 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 10:20:10,153]\u001b[0m Trial 35 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 10:20:11,904]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 10:20:13,713]\u001b[0m Trial 37 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 10:20:14,834]\u001b[0m Trial 38 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 10:20:16,664]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 10:20:18,262]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 10:20:20,933]\u001b[0m Trial 41 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-06-22 10:35:33,344]\u001b[0m Trial 42 finished with value: 0.19615870567894372 and parameters: {'lambda': 2.0283222074829014e-06, 'alpha': 3.4069783617098546e-06, 'max_depth': 9, 'eta': 6.745103959553076e-06, 'gamma': 1.4556121695870031e-05, 'n_estimators': 733, 'min_child_weight': 3, 'subsample': 0.8435375559322175}. Best is trial 2 with value: 0.19466914964027004.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 10:35:35,269]\u001b[0m Trial 43 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 10:35:42,268]\u001b[0m Trial 44 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 10:36:38,053]\u001b[0m Trial 45 pruned. Trial was pruned at iteration 46.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 10:36:39,814]\u001b[0m Trial 46 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 10:36:41,526]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 10:36:45,916]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
            "\u001b[32m[I 2021-06-22 10:36:47,538]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 0.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9Mr8CepKZiu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e80006d-5647-485e-a67a-0461b146a8ce"
      },
      "source": [
        "print('Best Trial: score {},\\nparams {}'.format(study_xgb.best_trial.value, study_xgb.best_trial.params))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Trial: score 0.19466914964027004,\n",
            "params {'lambda': 0.005943503728075847, 'alpha': 2.1627610787257848e-06, 'max_depth': 9, 'eta': 0.005207224083783965, 'gamma': 0.00021895503882644017, 'n_estimators': 813, 'min_child_weight': 4, 'subsample': 0.7418647364337652}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0MKj1vWKau2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "30c54bb9-fc45-49a2-fef3-1ba258b536bb"
      },
      "source": [
        "optuna.visualization.plot_param_importances(study_xgb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"0ed21ac8-e11d-4461-9b71-1043e1e2aead\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"0ed21ac8-e11d-4461-9b71-1043e1e2aead\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '0ed21ac8-e11d-4461-9b71-1043e1e2aead',\n",
              "                        [{\"cliponaxis\": false, \"hovertemplate\": [\"alpha (LogUniformDistribution): 0.0025000641312040847<extra></extra>\", \"gamma (LogUniformDistribution): 0.013492706814090795<extra></extra>\", \"eta (LogUniformDistribution): 0.046035990961007314<extra></extra>\", \"min_child_weight (IntUniformDistribution): 0.07826806295975589<extra></extra>\", \"max_depth (IntUniformDistribution): 0.09263670551552762<extra></extra>\", \"subsample (LogUniformDistribution): 0.1289693373784458<extra></extra>\", \"n_estimators (IntUniformDistribution): 0.25829911180281845<extra></extra>\", \"lambda (LogUniformDistribution): 0.37979802043715<extra></extra>\"], \"marker\": {\"color\": \"rgb(66,146,198)\"}, \"orientation\": \"h\", \"text\": [\"0.0025000641312040847\", \"0.013492706814090795\", \"0.046035990961007314\", \"0.07826806295975589\", \"0.09263670551552762\", \"0.1289693373784458\", \"0.25829911180281845\", \"0.37979802043715\"], \"textposition\": \"outside\", \"texttemplate\": \"%{text:.2f}\", \"type\": \"bar\", \"x\": [0.0025000641312040847, 0.013492706814090795, 0.046035990961007314, 0.07826806295975589, 0.09263670551552762, 0.1289693373784458, 0.25829911180281845, 0.37979802043715], \"y\": [\"alpha\", \"gamma\", \"eta\", \"min_child_weight\", \"max_depth\", \"subsample\", \"n_estimators\", \"lambda\"]}],\n",
              "                        {\"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Hyperparameter Importances\"}, \"xaxis\": {\"title\": {\"text\": \"Importance for Objective Value\"}}, \"yaxis\": {\"title\": {\"text\": \"Hyperparameter\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('0ed21ac8-e11d-4461-9b71-1043e1e2aead');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcxIZxmr3dez",
        "outputId": "b8075215-a940-4abb-e636-57ea8972811e"
      },
      "source": [
        "trial = study_xgb.best_trial\n",
        "xgb_params = trial.params\n",
        "xgb_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 2.1627610787257848e-06,\n",
              " 'eta': 0.005207224083783965,\n",
              " 'gamma': 0.00021895503882644017,\n",
              " 'lambda': 0.005943503728075847,\n",
              " 'max_depth': 9,\n",
              " 'min_child_weight': 4,\n",
              " 'n_estimators': 813,\n",
              " 'subsample': 0.7418647364337652}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsFPwKAq3hSC",
        "outputId": "fbfad74d-c66b-4094-cfa3-295d895e25dd"
      },
      "source": [
        "final_xgb_model = xgb.XGBRegressor(**xgb_params)\n",
        "final_xgb_model.fit(train_X, train_y, eval_metric='rmse')\n",
        "final_xgb_pred = final_xgb_model.predict(test_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa8BHA3o3jyJ",
        "outputId": "d06406a7-989c-4359-b841-ad619faff4cc"
      },
      "source": [
        "final_xgb_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([10.220038 ,  9.39824  ,  9.503799 , ..., 10.8020525, 10.499101 ,\n",
              "        9.708441 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "QtWwnrnf3lqv",
        "outputId": "a784f1f2-3253-4d2c-9a9f-42216dc267ed"
      },
      "source": [
        "plt.barh(train_X.columns, final_xgb_model.feature_importances_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 9 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7SwUqR13n3Z",
        "outputId": "57a6b750-f8eb-47ae-fc90-c0e765355d26"
      },
      "source": [
        "final_pred_sub = np.expm1(final_xgb_pred)\n",
        "final_pred_sub"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([27446.72 , 12066.125, 13409.583, ..., 49120.52 , 36281.86 ,\n",
              "       16454.924], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "q8T8aeh73qCV",
        "outputId": "b1959830-3cb2-4005-eee9-439ce3aa3a67"
      },
      "source": [
        "sub = pd.read_csv(PATH + 'test.csv')\n",
        "sub_df = pd.DataFrame({'transaction_id': sub['transaction_id'], 'transaction_real_price': final_pred_sub})\n",
        "sub_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>transaction_id</th>\n",
              "      <th>transaction_real_price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1145756</td>\n",
              "      <td>27446.720703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1198704</td>\n",
              "      <td>12066.125000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1222384</td>\n",
              "      <td>13409.583008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1179897</td>\n",
              "      <td>112344.523438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1223091</td>\n",
              "      <td>37538.347656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5458</th>\n",
              "      <td>1174640</td>\n",
              "      <td>50079.707031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5459</th>\n",
              "      <td>1175575</td>\n",
              "      <td>150977.171875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5460</th>\n",
              "      <td>1157024</td>\n",
              "      <td>49120.519531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5461</th>\n",
              "      <td>1136863</td>\n",
              "      <td>36281.859375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5462</th>\n",
              "      <td>1218921</td>\n",
              "      <td>16454.923828</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5463 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      transaction_id  transaction_real_price\n",
              "0            1145756            27446.720703\n",
              "1            1198704            12066.125000\n",
              "2            1222384            13409.583008\n",
              "3            1179897           112344.523438\n",
              "4            1223091            37538.347656\n",
              "...              ...                     ...\n",
              "5458         1174640            50079.707031\n",
              "5459         1175575           150977.171875\n",
              "5460         1157024            49120.519531\n",
              "5461         1136863            36281.859375\n",
              "5462         1218921            16454.923828\n",
              "\n",
              "[5463 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUM4WbBx3r8Q"
      },
      "source": [
        "sub_df.to_csv(PATH + 'submission_xgb_apt_extra_configuration.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI8Bi5fE3ykc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plENVUttKceO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}